# -*- coding: utf-8 -*-
"""waste models code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xAi83Yi7zaSVCCVzBuuvuR3AHHh9Wa3s
"""

from google.colab import drive
import os

# Mount your Google Drive
drive.mount('/content/drive')

# Define the dataset folder path
dataset_path = "/content/BDWaste"  # We'll use this as the main working directory

# If your dataset is in Drive, extract or copy it to /content/BDWaste
# Example: zip_path = "/content/drive/MyDrive/bdwaste.zip"

import zipfile
import shutil

# Path to ZIP file in Drive (edit this if you‚Äôre using a ZIP)
zip_path = "/content/drive/MyDrive/BDWaste.zip"

# Extract if ZIP file exists
if os.path.exists(zip_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall("/content/")
    print("‚úÖ Dataset extracted to /content/")
else:
    print("‚ö†Ô∏è ZIP file not found at the path provided.")

# OR if dataset is already a folder in Drive
# drive_folder_path = "/content/drive/MyDrive/BDWaste"
# shutil.copytree(drive_folder_path, dataset_path, dirs_exist_ok=True)

import os
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from glob import glob

# Define paths for Digestive and Indigestive folders
digestive_path = os.path.join(dataset_path, "Digestive")
indigestive_path = os.path.join(dataset_path, "Indigestive")

# Function to count total images
def count_images(folder):
    counts = {}
    for category in os.listdir(folder):
        path = os.path.join(folder, category)
        if os.path.isdir(path):
            counts[category] = len(glob(os.path.join(path, "*.*")))
    return counts

# Get counts
digestive_counts = count_images(digestive_path)
indigestive_counts = count_images(indigestive_path)
total_counts = {**digestive_counts, **indigestive_counts}

# Convert to DataFrame
df_counts = pd.DataFrame(list(total_counts.items()), columns=["Category", "Image Count"])

# Plot
plt.figure(figsize=(12, 5))
sns.barplot(data=df_counts, x="Category", y="Image Count")
plt.xticks(rotation=90)
plt.xlabel("Waste Categories")
plt.ylabel("Image Count")
plt.title("Image Count per Category in BDWaste Dataset")
plt.tight_layout()
plt.show()

# Print counts
print("\n‚úÖ Category-wise Image Count:")
for category, count in total_counts.items():
    print(f"üìå {category}: {count} images")

import os
import shutil
import random

# Original dataset path
original_path = "/content/BDWaste"

# New root for split dataset
split_path = "/content/BDWaste_Split"
train_path = os.path.join(split_path, "train")
val_path = os.path.join(split_path, "val")
test_path = os.path.join(split_path, "test")

# Function to split each category
def split_data(source_folder, train_folder, val_folder, test_folder, train_ratio=0.8, val_ratio=0.1):
    for category in os.listdir(source_folder):
        category_path = os.path.join(source_folder, category)
        if os.path.isdir(category_path):
            images = os.listdir(category_path)
            random.shuffle(images)

            total = len(images)
            train_end = int(total * train_ratio)
            val_end = train_end + int(total * val_ratio)

            splits = {
                train_folder: images[:train_end],
                val_folder: images[train_end:val_end],
                test_folder: images[val_end:]
            }

            for split_folder, files in splits.items():
                cat_dir = os.path.join(split_folder, category)
                os.makedirs(cat_dir, exist_ok=True)
                for file in files:
                    src = os.path.join(category_path, file)
                    dst = os.path.join(cat_dir, file)
                    shutil.copyfile(src, dst)

# Run the split for Digestive and Indigestive
for class_type in ["Digestive", "Indigestive"]:
    src = os.path.join(original_path, class_type)
    split_data(
        src,
        os.path.join(train_path, class_type),
        os.path.join(val_path, class_type),
        os.path.join(test_path, class_type)
    )

print("‚úÖ Dataset split into train (80%), val (10%), and test (10%)")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Image properties
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32

# Augmentation for training only
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    brightness_range=[0.8, 1.2],
    horizontal_flip=True
)

# No augmentation for val/test ‚Äî only normalization
val_test_datagen = ImageDataGenerator(rescale=1./255)

# Load images
train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

val_generator = val_test_datagen.flow_from_directory(
    val_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

test_generator = val_test_datagen.flow_from_directory(
    test_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False  # Important for test evaluation
)

print("‚úÖ Data generators ready: train, validation, test")

def save_model_artifacts(model, history, name):
    import os, json, pickle
    import matplotlib.pyplot as plt

    # Create directories
    os.makedirs("saved_models", exist_ok=True)
    os.makedirs("histories", exist_ok=True)
    os.makedirs("plots", exist_ok=True)

    # Save model
    model.save(f"saved_models/{name}.keras")

    # Save training history
    with open(f"histories/{name}_history.pkl", "wb") as f:
        pickle.dump(history.history, f)

    # Save accuracy plot
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f"{name} Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.savefig(f"plots/{name}_accuracy_plot.png")
    plt.close()

    # Save validation accuracy to JSON
    val_acc = history.history['val_accuracy'][-1]
    acc_path = "saved_models/model_val_accuracies.json"
    if os.path.exists(acc_path):
        with open(acc_path, "r") as f:
            results = json.load(f)
    else:
        results = {}
    results[name] = val_acc
    with open(acc_path, "w") as f:
        json.dump(results, f, indent=4)

from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def evaluate_model(model, model_name, test_generator):
    print(f"\nüîç Evaluating {model_name} on Test Set...")

    # Accuracy and loss
    test_loss, test_acc = model.evaluate(test_generator, verbose=1)
    print(f"\n‚úÖ {model_name} - Test Accuracy: {test_acc:.4f}")
    print(f"üß™ {model_name} - Test Loss: {test_loss:.4f}")

    # Predictions
    preds = model.predict(test_generator)
    y_pred = np.argmax(preds, axis=1)
    y_true = test_generator.classes
    labels = list(test_generator.class_indices.keys())

    # Classification Report
    print(f"\nüìä {model_name} - Classification Report:")
    print(classification_report(y_true, y_pred, target_names=labels))

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=labels, yticklabels=labels)
    plt.title(f'{model_name} - Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

import matplotlib.pyplot as plt

def plot_training_history(history, model_name="Model"):
    # Plot accuracy
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title(f'{model_name} - Training vs Validation Accuracy')
    plt.legend()
    plt.show()

    # Plot loss
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title(f'{model_name} - Training vs Validation Loss')
    plt.legend()
    plt.show()

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization

# Define the model (same structure, clean input)
model = Sequential([
    Input(shape=(224, 224, 3)),

    # Block 1
    Conv2D(32, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    # Block 2
    Conv2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    # Block 3
    Conv2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    # Classifier
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(train_generator.num_classes, activation='softmax')  # Output layer
])

# Compile the model
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# Model summary
model.summary()

import warnings
import os
import pickle
import matplotlib.pyplot as plt

# Suppress specific warnings
warnings.filterwarnings("ignore", category=UserWarning, module='keras.src.trainers.data_adapters.py_dataset_adapter')

# Train the model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=15,
    verbose=1
)

# Call the save function
save_model_artifacts(model, history, "Custom_CNN_model_waste_classifier")

# Plot training history
plot_training_history(history, model_name="Custom_CNN_model_waste_classifier")

from tensorflow.keras.models import load_model
Custom_CNN_model_waste_classifier = load_model("saved_models/Custom_CNN_model_waste_classifier.keras")

evaluate_model(Custom_CNN_model_waste_classifier, "Custom_CNN_model_waste_classifier", test_generator)

import tensorflow as tf
from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# Model architectures to evaluate
architectures = {
    "VGG16": VGG16,
    "MobileNetV2": MobileNetV2,
    "ResNet50": ResNet50
}

for name, base_fn in architectures.items():
    print(f"\nüîß Training model: {name}")

    base_model = base_fn(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

    # Freeze base layers
    for layer in base_model.layers:
        layer.trainable = False

    # Add custom head
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(256, activation='relu')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(train_generator.num_classes, activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=predictions)

    model.compile(optimizer=Adam(learning_rate=1e-4),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    history = model.fit(
        train_generator,
        validation_data=val_generator,
        epochs=15,
        callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],
        verbose=1
    )

    # Save everything neatly using your function
    save_model_artifacts(model, history, name)


print("\n‚úÖ All models trained and artifacts saved successfully!")

# Plot training history
plot_training_history(history, model_name="VGG16")
plot_training_history(history, model_name="MobileNetV2")
plot_training_history(history, model_name="ResNet50")

from tensorflow.keras.models import load_model

# Load all saved models properly
models = {}
models["VGG16"] = load_model("saved_models/VGG16.keras")
models["MobileNetV2"] = load_model("saved_models/MobileNetV2.keras")
models["ResNet50"] = load_model("saved_models/ResNet50.keras")

# STEP 4: Evaluate All Models
evaluate_model(models["VGG16"], "VGG16", test_generator)
evaluate_model(models["MobileNetV2"], "MobileNetV2", test_generator)
evaluate_model(models["ResNet50"], "ResNet50", test_generator)

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

# Build the model
base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)  # You can change units if needed
x = Dropout(0.5)(x)  # ‚úÖ Fixed dropout at 0.5
outputs = Dense(train_generator.num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=outputs)

# Compile the model
model.compile(
    optimizer=Adam(learning_rate=1e-4),  # Fixed learning rate
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model once
model.fit(train_generator,
          validation_data=val_generator,
          epochs=15,
          verbose=1)


# Example usage after training your model
save_model_artifacts(model, history, "Tuned_Mobilenetv2_waste_classifier")

# Plot training history
plot_training_history(history, model_name="Tuned_Mobilenetv2_waste_classifier")

from tensorflow.keras.models import load_model

tuned_mobilenetv2_model_waste_classifier =load_model("saved_models/Tuned_Mobilenetv2_waste_classifier.keras")

evaluate_model(tuned_mobilenetv2_model_waste_classifier, "Tuned_Mobilenetv2_waste_classifier", test_generator)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense, Input
from tensorflow.keras.optimizers import Adam, RMSprop, SGD

# Define your custom CNN with adjustable hyperparameters
def build_custom_cnn(optimizer='adam', learning_rate=1e-4, dropout_rate=0.5, filters=[32, 64, 128], num_classes=2):
    model = Sequential([
        Input(shape=(224, 224, 3)),

        Conv2D(filters[0], (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(),

        Conv2D(filters[1], (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(),

        Conv2D(filters[2], (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(),

        Flatten(),
        Dense(256, activation='relu'),
        Dropout(dropout_rate),
        Dense(num_classes, activation='softmax')
    ])

    # Choose optimizer
    if optimizer == 'adam':
        opt = Adam(learning_rate=learning_rate)
    elif optimizer == 'rmsprop':
        opt = RMSprop(learning_rate=learning_rate)
    elif optimizer == 'sgd':
        opt = SGD(learning_rate=learning_rate, momentum=0.9)

    model.compile(optimizer=opt,
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    return model
model = build_custom_cnn(
    optimizer='adam',
    learning_rate=1e-4,
    dropout_rate=0.5,
    filters=[32, 64, 128],
    num_classes=2
)

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=15,
    verbose=1
)

# Save the model, history, and plot in structured folders
save_model_artifacts(model, history, "Tuned_Custom_CNN_model_waste_classifier")

# Plot training history
plot_training_history(history, model_name="Tuned_Custom_CNN_model_waste_classifier")

tuned_Custom_CNN_model_waste_classifier =load_model("saved_models/Tuned_Custom_CNN_model_waste_classifier.keras")

evaluate_model(tuned_Custom_CNN_model_waste_classifier, "Tuned_Custom_CNN_model_waste_classifier", test_generator)

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

def compare_models(models_dict, test_generator):
    results = []

    for name, model in models_dict.items():
        print(f"\nüîç Evaluating {name}...")

        loss, acc = model.evaluate(test_generator, verbose=0)
        y_pred = np.argmax(model.predict(test_generator), axis=1)
        y_true = test_generator.classes
        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)

        f1 = report['weighted avg']['f1-score']
        precision = report['weighted avg']['precision']
        recall = report['weighted avg']['recall']

        results.append({
            'Model': name,
            'Test Accuracy': round(acc, 4),
            'Test Loss': round(loss, 4),
            'Precision': round(precision, 4),
            'Recall': round(recall, 4),
            'F1-Score': round(f1, 4)
        })

    return results

# Models to compare
models = {
    "Tuned_Custom_CNN_model_waste_classifier": tuned_Custom_CNN_model_waste_classifier,
    "Tuned_Mobilenetv2_model_waste_classifier": tuned_mobilenetv2_model_waste_classifier
}


# Run comparison
comparison_results = compare_models(models, test_generator)
import pandas as pd


df_results = pd.DataFrame(comparison_results)
df_results.set_index('Model', inplace=True)
display(df_results)