# -*- coding: utf-8 -*-
"""Code waste Classfication.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tx3kbJq2ozm0jPBxGvr_abrKq8_JCGFy
"""

from google.colab import drive
import os

# Mount your Google Drive
drive.mount('/content/drive')

# Define the dataset folder path
dataset_path = "/content/BDWaste"  # We'll use this as the main working directory

# If your dataset is in Drive, extract or copy it to /content/BDWaste
# Example: zip_path = "/content/drive/MyDrive/bdwaste.zip"

import zipfile
import shutil

# Path to ZIP file in Drive (edit this if you‚Äôre using a ZIP)
zip_path = "/content/drive/MyDrive/BDWaste.zip"

# Extract if ZIP file exists
if os.path.exists(zip_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall("/content/")
    print("‚úÖ Dataset extracted to /content/")
else:
    print("‚ö†Ô∏è ZIP file not found at the path provided.")

# OR if dataset is already a folder in Drive
# drive_folder_path = "/content/drive/MyDrive/BDWaste"
# shutil.copytree(drive_folder_path, dataset_path, dirs_exist_ok=True)

import os
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from glob import glob

# Define paths for Digestive and Indigestive folders
digestive_path = os.path.join(dataset_path, "Digestive")
indigestive_path = os.path.join(dataset_path, "Indigestive")

# Function to count total images
def count_images(folder):
    counts = {}
    for category in os.listdir(folder):
        path = os.path.join(folder, category)
        if os.path.isdir(path):
            counts[category] = len(glob(os.path.join(path, "*.*")))
    return counts

# Get counts
digestive_counts = count_images(digestive_path)
indigestive_counts = count_images(indigestive_path)
total_counts = {**digestive_counts, **indigestive_counts}

# Convert to DataFrame
df_counts = pd.DataFrame(list(total_counts.items()), columns=["Category", "Image Count"])

# Plot
plt.figure(figsize=(12, 5))
sns.barplot(data=df_counts, x="Category", y="Image Count")
plt.xticks(rotation=90)
plt.xlabel("Waste Categories")
plt.ylabel("Image Count")
plt.title("Image Count per Category in BDWaste Dataset")
plt.tight_layout()
plt.show()

# Print counts
print("\n‚úÖ Category-wise Image Count:")
for category, count in total_counts.items():
    print(f"üìå {category}: {count} images")

import os
import shutil
import random

# Original dataset path
original_path = "/content/BDWaste"

# New root for split dataset
split_path = "/content/BDWaste_Split"
train_path = os.path.join(split_path, "train")
val_path = os.path.join(split_path, "val")
test_path = os.path.join(split_path, "test")

# Function to split each category
def split_data(source_folder, train_folder, val_folder, test_folder, train_ratio=0.8, val_ratio=0.1):
    for category in os.listdir(source_folder):
        category_path = os.path.join(source_folder, category)
        if os.path.isdir(category_path):
            images = os.listdir(category_path)
            random.shuffle(images)

            total = len(images)
            train_end = int(total * train_ratio)
            val_end = train_end + int(total * val_ratio)

            splits = {
                train_folder: images[:train_end],
                val_folder: images[train_end:val_end],
                test_folder: images[val_end:]
            }

            for split_folder, files in splits.items():
                cat_dir = os.path.join(split_folder, category)
                os.makedirs(cat_dir, exist_ok=True)
                for file in files:
                    src = os.path.join(category_path, file)
                    dst = os.path.join(cat_dir, file)
                    shutil.copyfile(src, dst)

# Run the split for Digestive and Indigestive
for class_type in ["Digestive", "Indigestive"]:
    src = os.path.join(original_path, class_type)
    split_data(
        src,
        os.path.join(train_path, class_type),
        os.path.join(val_path, class_type),
        os.path.join(test_path, class_type)
    )

print("‚úÖ Dataset split into train (80%), val (10%), and test (10%)")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Image properties
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32

# Augmentation for training only
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    brightness_range=[0.8, 1.2],
    horizontal_flip=True
)

# No augmentation for val/test ‚Äî only normalization
val_test_datagen = ImageDataGenerator(rescale=1./255)

# Load images
train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

val_generator = val_test_datagen.flow_from_directory(
    val_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

test_generator = val_test_datagen.flow_from_directory(
    test_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False  # Important for test evaluation
)

print("‚úÖ Data generators ready: train, validation, test")

def save_model_artifacts(model, history, name):
    import os, json, pickle
    import matplotlib.pyplot as plt

    # Create directories
    os.makedirs("saved_models", exist_ok=True)
    os.makedirs("histories", exist_ok=True)
    os.makedirs("plots", exist_ok=True)

    # Save model
    model.save(f"saved_models/{name}.keras")

    # Save training history
    with open(f"histories/{name}_history.pkl", "wb") as f:
        pickle.dump(history.history, f)

    # Save accuracy plot
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f"{name} Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.savefig(f"plots/{name}_accuracy_plot.png")
    plt.close()

    # Save validation accuracy to JSON
    val_acc = history.history['val_accuracy'][-1]
    acc_path = "saved_models/model_val_accuracies.json"
    if os.path.exists(acc_path):
        with open(acc_path, "r") as f:
            results = json.load(f)
    else:
        results = {}
    results[name] = val_acc
    with open(acc_path, "w") as f:
        json.dump(results, f, indent=4)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization

# Define the model (same structure, clean input)
model = Sequential([
    Input(shape=(224, 224, 3)),

    # Block 1
    Conv2D(32, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    # Block 2
    Conv2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    # Block 3
    Conv2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(pool_size=(2, 2)),

    # Classifier
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(train_generator.num_classes, activation='softmax')  # Output layer
])

# Compile the model
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# Model summary
model.summary()

import warnings
import os
import pickle
import matplotlib.pyplot as plt

# Suppress specific warnings
warnings.filterwarnings("ignore", category=UserWarning, module='keras.src.trainers.data_adapters.py_dataset_adapter')

# Train the model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=15,
    verbose=1
)

# Call the save function
save_model_artifacts(model, history, "Custom_CNN_model_waste_classifier")

import matplotlib.pyplot as plt

# Plot accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training vs Validation Accuracy')
plt.legend()
plt.show()

# Plot loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training vs Validation Loss')
plt.legend()
plt.show()

from tensorflow.keras.models import load_model
Custom_CNN_model_waste_classifier = load_model("saved_models/Custom_CNN_model_waste_classifier.keras")

from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

def evaluate_model(model, model_name, test_generator):
    print(f"\nüîç Evaluating {model_name} on Test Set...")

    # Accuracy and loss
    test_loss, test_acc = model.evaluate(test_generator, verbose=1)
    print(f"\n‚úÖ {model_name} - Test Accuracy: {test_acc:.4f}")
    print(f"üß™ {model_name} - Test Loss: {test_loss:.4f}")

    # Predictions
    preds = model.predict(test_generator)
    y_pred = np.argmax(preds, axis=1)
    y_true = test_generator.classes
    labels = list(test_generator.class_indices.keys())

    # Classification Report
    print(f"\nüìä {model_name} - Classification Report:")
    print(classification_report(y_true, y_pred, target_names=labels))

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=labels, yticklabels=labels)
    plt.title(f'{model_name} - Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

evaluate_model(Custom_CNN_model_waste_classifier, "Custom_CNN_model_waste_classifier", test_generator)

# Evaluate on test set
test_loss, test_acc = model.evaluate(test_generator)
print(f"\nüéØ Test Accuracy: {test_acc:.4f}")
print(f"üß™ Test Loss: {test_loss:.4f}")

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Get predictions
Y_pred = model.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)

# True labels
y_true = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

# Classification report
print("üìä Classification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_labels))

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot
plt.figure(figsize=(12, 8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

import tensorflow as tf
from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import pickle
import json
import os

# Model architectures to evaluate
architectures = {
    "VGG16": VGG16,
    "MobileNetV2": MobileNetV2,
    "ResNet50": ResNet50
}

results = {}

# Create output directory
os.makedirs("saved_models", exist_ok=True)
os.makedirs("plots", exist_ok=True)
os.makedirs("histories", exist_ok=True)

for name, base_fn in architectures.items():
    print(f"\nüîß Training model: {name}")

    base_model = base_fn(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

    # Freeze base layers
    for layer in base_model.layers:
        layer.trainable = False

    # Add custom head
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(256, activation='relu')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(train_generator.num_classes, activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=predictions)

    model.compile(optimizer=Adam(learning_rate=1e-4),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    history = model.fit(
        train_generator,
        validation_data=val_generator,
        epochs=15,
        callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],
        verbose=1
    )

    # Save final validation accuracy
    val_acc = history.history['val_accuracy'][-1]
    results[name] = val_acc

    # Save model
    model.save(f"saved_models/{name}_waste_classifier.keras")

    # Save training history
    with open(f"histories/{name}_history.pkl", 'wb') as f:
        pickle.dump(history.history, f)

    # Plot and save accuracy curve
    plt.figure()
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f'{name} Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.savefig(f"plots/{name}_accuracy_plot.png")
    plt.close()

    # Call save_model_artifacts after each model is trained
    save_model_artifacts(model, history, name)  # Call the function that you already defined

# Save all validation accuracies to JSON
with open("saved_models/model_val_accuracies.json", "w") as f:
    json.dump(results, f, indent=4)

# Print comparison
print("\nüìä Model Validation Accuracies:")
for model_name, acc in results.items():
    print(f"{model_name}: {acc:.4f}")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import load_model
from tensorflow.keras.optimizers import Adam

# STEP 1: Load Test Generator
test_path = "/content/BDWaste_Split/test"

test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# STEP 2: Load and Recompile Models (to remove warning)
vgg_model = load_model("saved_models/VGG16_waste_classifier.keras")
mobilenet_model = load_model("saved_models/MobileNetV2_waste_classifier.keras")
resNet50_model = load_model("saved_models/ResNet50_waste_classifier.keras")

# ‚úÖ Recompile to build metrics correctly
vgg_model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])
mobilenet_model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])
resNet50_model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# STEP 3: Evaluation Function
def evaluate_model_on_test(model, model_name):
    print(f"\nüîç Evaluating {model_name} on Test Set")

    # Test accuracy & loss
    test_loss, test_acc = model.evaluate(test_generator, verbose=1)
    print(f"\n‚úÖ {model_name} - Test Accuracy: {test_acc:.4f}")
    print(f"üß™ {model_name} - Test Loss: {test_loss:.4f}")

    # Predictions
    predictions = model.predict(test_generator)
    y_pred = np.argmax(predictions, axis=1)
    y_true = test_generator.classes
    class_labels = list(test_generator.class_indices.keys())

    # Classification report
    print(f"\nüìä {model_name} - Classification Report")
    print(classification_report(y_true, y_pred, target_names=class_labels))

    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_labels, yticklabels=class_labels)
    plt.title(f'{model_name} - Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

# STEP 4: Evaluate All Models
evaluate_model_on_test(vgg_model, "VGG16")
evaluate_model_on_test(mobilenet_model, "MobileNetV2")
evaluate_model_on_test(resNet50_model, "ResNet50")

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

# Build the model
base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)  # You can change units if needed
x = Dropout(0.5)(x)  # ‚úÖ Fixed dropout at 0.5
outputs = Dense(train_generator.num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=outputs)

# Compile the model
model.compile(
    optimizer=Adam(learning_rate=1e-4),  # Fixed learning rate
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model once
model.fit(train_generator,
          validation_data=val_generator,
          epochs=15,  # Adjust epochs as needed
          verbose=1)


# Example usage after training your model
save_model_artifacts(model, history, "Tuned_Mobilenetv2_waste_classifier")

from tensorflow.keras.models import load_model

tuned_mobilenetv2_model_waste_classifier =load_model("saved_models/Tuned_Mobilenetv2_waste_classifier.keras")

evaluate_model(tuned_mobilenetv2_model_waste_classifier, "Tuned_Mobilenetv2_waste_classifier", test_generator)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense, Input
from tensorflow.keras.optimizers import Adam, RMSprop, SGD

# Define your custom CNN with adjustable hyperparameters
def build_custom_cnn(optimizer='adam', learning_rate=1e-4, dropout_rate=0.5, filters=[32, 64, 128], num_classes=2):
    model = Sequential([
        Input(shape=(224, 224, 3)),

        Conv2D(filters[0], (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(),

        Conv2D(filters[1], (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(),

        Conv2D(filters[2], (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(),

        Flatten(),
        Dense(256, activation='relu'),
        Dropout(dropout_rate),
        Dense(num_classes, activation='softmax')
    ])

    # Choose optimizer
    if optimizer == 'adam':
        opt = Adam(learning_rate=learning_rate)
    elif optimizer == 'rmsprop':
        opt = RMSprop(learning_rate=learning_rate)
    elif optimizer == 'sgd':
        opt = SGD(learning_rate=learning_rate, momentum=0.9)

    model.compile(optimizer=opt,
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    return model
model = build_custom_cnn(
    optimizer='adam',
    learning_rate=1e-4,
    dropout_rate=0.5,
    filters=[32, 64, 128],
    num_classes=2
)

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=15,
    verbose=1
)

# Save the model, history, and plot in structured folders
save_model_artifacts(model, history, "Tuned_Custom_CNN_model_waste_classifier")

tuned_Custom_CNN_model_waste_classifier =load_model("saved_models/Tuned_Custom_CNN_model_waste_classifier.keras")

evaluate_model(tuned_Custom_CNN_model_waste_classifier, "Tuned_Custom_CNN_model_waste_classifier", test_generator)

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

def compare_models(models_dict, test_generator):
    results = []

    for name, model in models_dict.items():
        print(f"\nüîç Evaluating {name}...")

        loss, acc = model.evaluate(test_generator, verbose=0)
        y_pred = np.argmax(model.predict(test_generator), axis=1)
        y_true = test_generator.classes
        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)

        f1 = report['weighted avg']['f1-score']
        precision = report['weighted avg']['precision']
        recall = report['weighted avg']['recall']

        results.append({
            'Model': name,
            'Test Accuracy': round(acc, 4),
            'Test Loss': round(loss, 4),
            'Precision': round(precision, 4),
            'Recall': round(recall, 4),
            'F1-Score': round(f1, 4)
        })

    return results

# Models to compare
models = {
    "Tuned_Custom_CNN_model_waste_classifier": tuned_Custom_CNN_model_waste_classifier,
    "Tuned_Mobilenetv2_model_waste_classifier": tuned_mobilenetv2_model_waste_classifier
}


# Run comparison
comparison_results = compare_models(models, test_generator)
import pandas as pd


df_results = pd.DataFrame(comparison_results)
df_results.set_index('Model', inplace=True)
display(df_results)
