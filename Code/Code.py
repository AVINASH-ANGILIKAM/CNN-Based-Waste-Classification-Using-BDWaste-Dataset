# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FG2pvyDul8ZVc-xEJE1stsig2OxjDPQH
"""

from google.colab import drive
import zipfile
import os

# Mount Google Drive
drive.mount('/content/drive')

# Define dataset path
dataset_zip_path = "/content/drive/My Drive/BDWaste.zip"  # Update this path if necessary
extract_path = "/content/BDWaste"

# Extract dataset
with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Dataset extracted successfully!")

import os

dataset_path = "/content/BDWaste"  # Update this path

# Function to count images in each main subfolder
def count_images_in_category(category_path):
    image_extensions = ('.png', '.jpg', '.jpeg', '.webp', '.tiff')
    total_images = 0

    for root, _, files in os.walk(category_path):  # Recursively scan
        total_images += sum(1 for file in files if file.lower().endswith(image_extensions))

    return total_images

# Scan BDWaste dataset
print("\n📂 BDWaste contains:")
total_count = 0

for category in sorted(os.listdir(dataset_path)):  # Sorting for consistent order
    category_path = os.path.join(dataset_path, category)
    if os.path.isdir(category_path):  # Only process directories
        image_count = count_images_in_category(category_path)
        total_count += image_count
        print(f"   🗂 {category}: {image_count} images")

print(f"   📊 Total images in BDWaste: {total_count}\n")

import os

# Define dataset path
dataset_inner_path = "/content/BDWaste/BDWaste"

# Check class folders
print("Dataset Structure:")
for category in os.listdir(dataset_inner_path):
    category_path = os.path.join(dataset_inner_path, category)
    if os.path.isdir(category_path):
        print(f"📂 {category} → {len(os.listdir(category_path))} subfolders")

# Check inside one sample subfolder
sample_subfolder = os.path.join(dataset_inner_path, "Biodegradable")  # Update as needed
if os.path.isdir(sample_subfolder):
    print(f"\n🔍 Sample subfolder: {sample_subfolder}")
    print(f"Contents: {os.listdir(sample_subfolder)[:5]}")  # Show only first 5

import os
import shutil
import random

# Define dataset paths
dataset_inner_path = "/content/BDWaste/BDWaste"
test_folder = "/content/BDWaste/Test"

# Define class folders
digestive_src = os.path.join(dataset_inner_path, "Digestive")
indigestive_src = os.path.join(dataset_inner_path, "Indigestive")

digestive_dst = os.path.join(test_folder, "Digestive")
indigestive_dst = os.path.join(test_folder, "Indigestive")

# Ensure test directories exist
os.makedirs(digestive_dst, exist_ok=True)
os.makedirs(indigestive_dst, exist_ok=True)

# Function to find and move 10% of images from sub-subfolders
def move_images_to_test(src_class_folder, dst_class_folder, percentage=10):
    all_images = []

    # Loop through all subfolders and collect images
    for subfolder in os.listdir(src_class_folder):
        subfolder_path = os.path.join(src_class_folder, subfolder)
        if os.path.isdir(subfolder_path):  # Only process folders
            for inner_subfolder in os.listdir(subfolder_path):  # Go deeper
                inner_subfolder_path = os.path.join(subfolder_path, inner_subfolder)
                if os.path.isdir(inner_subfolder_path):
                    images = [os.path.join(inner_subfolder_path, f)
                              for f in os.listdir(inner_subfolder_path)
                              if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
                    all_images.extend(images)

    # Move 10% of images
    num_to_move = int(len(all_images) * (percentage / 100))
    images_to_move = random.sample(all_images, min(num_to_move, len(all_images)))

    for img_path in images_to_move:
        img_name = os.path.basename(img_path)
        shutil.move(img_path, os.path.join(dst_class_folder, img_name))  # Move to correct test folder

# Move images to the Test set
move_images_to_test(digestive_src, digestive_dst)
move_images_to_test(indigestive_src, indigestive_dst)

print("\n✅ Test Set (10%) successfully created with images in correct folders!")

print(f"Digestive (Test Set): {len(os.listdir(digestive_dst))} images")
print(f"Indigestive (Test Set): {len(os.listdir(indigestive_dst))} images")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define test image generator (No Augmentation)
test_datagen = ImageDataGenerator(rescale=1.0/255.0)

# Load test set
test_generator = test_datagen.flow_from_directory(
    test_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    shuffle=False  # No shuffling for test set
)

print(f"✅ Test images loaded successfully: {test_generator.samples}")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define constants
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

# Define dataset paths
dataset_inner_path = "/content/BDWaste/BDWaste"  # Main dataset (Biodegradable, Indigestive)
test_folder = "/content/BDWaste/Test"  # Separate test dataset

# ✅ Apply data augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 80% Train, 10% Validation
)

# ✅ Load Training Data (80%)
train_generator = train_datagen.flow_from_directory(
    dataset_inner_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='training'
)

# ✅ Load Validation Data (10%)
val_generator = train_datagen.flow_from_directory(
    dataset_inner_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='validation'
)

# ✅ Load Test Data (10%) - No Augmentation
test_datagen = ImageDataGenerator(rescale=1.0/255.0)

test_generator = test_datagen.flow_from_directory(
    test_folder,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=False  # No shuffling for test set
)

# ✅ Print dataset summary
print(f"\n✅ Dataset Split:")
print(f"Training Images: {train_generator.samples}")
print(f"Validation Images: {val_generator.samples}")
print(f"Test Images: {test_generator.samples}")

import numpy as np
import matplotlib.pyplot as plt

# ✅ Get a batch of augmented images
sample_batch, sample_labels = next(train_generator)

# ✅ Display first 5 augmented images
plt.figure(figsize=(10, 5))
for i in range(5):
    plt.subplot(1, 5, i+1)
    plt.imshow(sample_batch[i])
    plt.axis('off')
plt.show()

import os
import matplotlib.pyplot as plt
import seaborn as sns
from glob import glob

# Define the confirmed dataset path
bdwaste_path = "/content/BDWaste/BDWaste"  # Adjusted based on the actual folder structure

# Define the paths for Digestive and Indigestive folders
digestive_path = os.path.join(bdwaste_path, "Digestive")
indigestive_path = os.path.join(bdwaste_path, "Indigestive")

# Ensure paths exist
if not os.path.exists(digestive_path):
    raise FileNotFoundError("⚠️ Digestive folder not found!")
if not os.path.exists(indigestive_path):
    raise FileNotFoundError("⚠️ Indigestive folder not found!")

print(f"\n✅ Digestive folder confirmed: {digestive_path}")
print(f"✅ Indigestive folder confirmed: {indigestive_path}")

# Dictionary to store image counts
image_counts = {"Digestive": {}, "Indigestive": {}}

# Count images in Digestive
print("\n📂 Counting images in Digestive categories:")
digestive_categories = [d for d in os.listdir(digestive_path) if os.path.isdir(os.path.join(digestive_path, d))]
for category in digestive_categories:
    category_path = os.path.join(digestive_path, category)
    image_files = glob(os.path.join(category_path, "**", "*.*"), recursive=True)
    image_counts["Digestive"][category] = len(image_files)
    print(f"  📌 {category}: {len(image_files)} images")

# Count images in Indigestive
print("\n📂 Counting images in Indigestive categories:")
indigestive_categories = [d for d in os.listdir(indigestive_path) if os.path.isdir(os.path.join(indigestive_path, d))]
for category in indigestive_categories:
    category_path = os.path.join(indigestive_path, category)
    image_files = glob(os.path.join(category_path, "**", "*.*"), recursive=True)
    image_counts["Indigestive"][category] = len(image_files)
    print(f"  📌 {category}: {len(image_files)} images")

# Step 6: Visualize Image Counts for Digestive & Indigestive
for folder in ["Digestive", "Indigestive"]:
    if folder in image_counts and image_counts[folder]:
        plt.figure(figsize=(12, 5))
        sns.barplot(x=list(image_counts[folder].keys()),
                    y=list(image_counts[folder].values()),
                    hue=list(image_counts[folder].keys()),
                    legend=False,
                    palette="coolwarm")
        plt.xticks(rotation=90)
        plt.xlabel("Waste Categories")
        plt.ylabel("Number of Images")
        plt.title(f"BDWaste Dataset - Image Count in {folder}")
        plt.show()

import os
import shutil
import random
import cv2
import numpy as np
import matplotlib.pyplot as plt
from glob import glob
from google.colab import drive
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img

# Mount Google Drive
drive.mount('/content/drive')

# Define dataset paths
bdwaste_path = "/content/BDWaste/BDWaste"  # Change if needed
digestive_path = os.path.join(bdwaste_path, "Digestive")
indigestive_path = os.path.join(bdwaste_path, "Indigestive")

# Define the output directory for the new oversampled dataset
output_path = "/content/BDWaste_Oversampled"
os.makedirs(output_path, exist_ok=True)

def augment_and_save_images(category_path, output_folder, target_count, augment=True):
    """
    Oversample images by either duplicating or augmenting.
    Saves the images in the output folder.

    :param category_path: Path to the category folder
    :param output_folder: Path to save oversampled images
    :param target_count: Number of images required after oversampling
    :param augment: Whether to apply augmentation (default: True)
    """
    # Get list of existing images
    image_files = glob(os.path.join(category_path, "*.*"))

    # Create output directory if not exists
    os.makedirs(output_folder, exist_ok=True)

    # Augmentation setup
    datagen = ImageDataGenerator(
        rotation_range=30,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )

    # Duplicate/Augment images until we reach target count
    current_count = len(image_files)
    while current_count < target_count:
        img_path = random.choice(image_files)
        img = load_img(img_path)
        img_array = img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)

        if augment:
            for batch in datagen.flow(img_array, batch_size=1):
                new_img = array_to_img(batch[0])
                new_img_name = f"aug_{current_count}.jpg"
                new_img.save(os.path.join(output_folder, new_img_name))
                current_count += 1
                if current_count >= target_count:
                    break
        else:
            new_img_name = f"dup_{current_count}.jpg"
            shutil.copy(img_path, os.path.join(output_folder, new_img_name))
            current_count += 1

    print(f"✅ Oversampled to {target_count} images in {output_folder}")

# Find the max image count in any category
category_counts = {}

for main_folder, folder_path in [("Digestive", digestive_path), ("Indigestive", indigestive_path)]:
    for category in os.listdir(folder_path):
        category_path = os.path.join(folder_path, category)
        if os.path.isdir(category_path):
            image_count = len(glob(os.path.join(category_path, "*.*")))
            category_counts[f"{main_folder}/{category}"] = image_count

max_count = max(category_counts.values())  # Maximum number of images in any category

print(f"\n🔹 Max image count found: {max_count} (Target for Oversampling)")

# Oversample each category
for main_folder, folder_path in [("Digestive", digestive_path), ("Indigestive", indigestive_path)]:
    for category in os.listdir(folder_path):
        category_path = os.path.join(folder_path, category)
        output_folder = os.path.join(output_path, main_folder, category)

        if os.path.isdir(category_path):
            current_count = len(glob(os.path.join(category_path, "*.*")))
            if current_count < max_count:
                augment_and_save_images(category_path, output_folder, max_count, augment=True)
            else:
                # Copy original images if already at max count
                shutil.copytree(category_path, output_folder, dirs_exist_ok=True)
                print(f"✅ {category} already at {max_count}, copied without changes.")
